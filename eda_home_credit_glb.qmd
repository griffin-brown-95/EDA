---
title: "EDA - Home Credit"
author: "Griffin Brown"
affiliation-title: "University of Utah"
date: last-modified
title-block-style: default
title-block-banner: "#219ebc"
format: 
  html:
      embed-resources: true
      theme: flatly
      code-block-bg: true
      code-block-border-left: "#3ABFC0"
      highlight-style: printing
      toc: true
execute:
    message: false
    warning: false
    error: false
    echo: true
---

#changes \## Load Packages

```{r setup}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(skimr)
library(janitor)
library(fastDummies)
library(corrplot)
library(corrr)
library(knitr)
```



## Load Data Sets

```{r data}

app_train <- read.csv("C:\\Users\\gbrown\\OneDrive - uolf.org\\Desktop\\Masters\\IS 6812-001 Seminar 2\\home_credit\\application_train.csv")

```

## A quick glance

We can see that the approval for a loan is fairly rare, with a 8% approval rating.

```{r glance}
#app_train$TARGET <- factor(app_train$TARGET)

app_train %>%  
  count(TARGET) %>% 
  mutate(perc = n/sum(n))
```

Here is the distribution visually.

```{r glance graph}
app_train %>% 
  mutate(TARGET = factor(TARGET)) %>% 
  count(TARGET) %>% 
  mutate(perc = n / sum(n)) %>% 
  ggplot(aes(x = TARGET, y = perc)) +
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic()
```

## Find Missing Values

There is a lot of missing data in the set.
- not much information for imputation if missing

```{r}

count_missings <- function(x) sum(is.na(x))

# no need to display all the missing columns, but 91 have missing values.
app_train %>%
  summarize_all(count_missings) %>%
  select_if(function(x) x > 0)

```

## Weird looking data

There are a couple weird looking data points, DAYS_EMPLOYED and AMT_INCOME_TOTAL immediately jumped out at me. I will not show the summary for readers sake.

```{r}
# app_train %>% 
#   summary()
```

## Data Cleaning

### DAYS_EMPLOYED

Looking at DAYS_EMPLOYED, there seems to be a huge positive number (we expect negative) of 365243. This is particularly in the "Pensioner" NAME_INCOME_TYPE category.

```{r}
# this plot serves to add all the DAYS_EMPLOYED up by NAME_INCOME_TYPE
app_train %>% 
  group_by(NAME_INCOME_TYPE) %>%
  summarize(Total_DAYS_EMPLOYED = sum(DAYS_EMPLOYED, na.rm = TRUE)) %>% 
  ggplot(aes(x = NAME_INCOME_TYPE, y = Total_DAYS_EMPLOYED, fill = NAME_INCOME_TYPE)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We can further see that this number seems to be some arbitrary number that is assigned to this category.

```{r}
app_train %>% 
  filter(DAYS_EMPLOYED == 365243) %>% 
  nrow()
```

### AMT_INCOME_TOTAL

This variable has some outliers as well. It looks to me like this is their income multiplied by 100. The stakeholder should be followed up with in order to figure this out for sure. Either way, the top responses do not make sense. I will take these rows out.

```{r}

# huge outliers
app_train %>% 
  mutate(TARGET = factor(TARGET)) %>% 
  ggplot()+
  geom_boxplot(aes(x = TARGET, y = AMT_INCOME_TOTAL))+
  scale_y_continuous(labels = scales::comma)

# top AMT_INCOME_TOTAL
app_train %>% 
  select(AMT_INCOME_TOTAL) %>% 
  arrange(desc(AMT_INCOME_TOTAL)) %>% 
  slice_max(order_by = AMT_INCOME_TOTAL, n = 10)
```

The question remains, how would we like to approach these two variables. As a pensioneer, maybe they never have worked, so perhaps 0 would work as a replacement to 365243. For now, I will give it the mean but this can easily be changed with further context. As I mentioned before, I will be taking the top outliers for AMT_TOTAL_INCOME out of the dataset completely.

```{r}
mean_days_employed <- app_train %>% 
  filter(DAYS_EMPLOYED != 365243) %>% 
  summarise(mean_value = mean(DAYS_EMPLOYED, na.rm = TRUE)) %>% 
  pull(mean_value)

app_train <- app_train %>% 
  mutate(DAYS_EMPLOYED = ifelse(DAYS_EMPLOYED == 365243,
                                mean_days_employed,
                                DAYS_EMPLOYED)) %>% 
  filter(AMT_INCOME_TOTAL <= 9000000)
```

## Numeric Predictors

For missing values, I will be giving the mean to NA variables.

```{r}

# function to create mean for numeric variables
app_train[] <- lapply(app_train, function(x) {
  if(is.numeric(x)) {
    x[is.na(x)] <- median(x, na.rm = TRUE)
  }
  return(x)
})

## no more missing values, no need to display
# app_train %>%
#   summarize_all(count_missings)
```

### I will use a correlation matrix to find strong numeric predictors.

```{r}
numerical_app_train <- app_train %>% 
  select(-SK_ID_CURR) %>%
  select(where(is.numeric))
head(numerical_app_train)

cor_matrix <- cor(numerical_app_train, use = "complete.obs")
cor_matrix['TARGET',] %>% 
  abs() %>% 
  sort(decreasing = TRUE) %>% 
  head(20) %>% 
  kable(caption = 'Top 20 Correlations with TARGET')

corrplot(cor_matrix, method = "color", type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45, tl.cex = 0.2)

```

### Logistic Regression

```{r}
head(numerical_app_train)
glm(TARGET ~ ., data = numerical_app_train) %>% summary()

```

-   CNT_CHILDREN

-   AMT_CREDIT

-   AMT_ANNUITY

-   AMT_GOODS_PRICE

-   DAYS_BIRTH

-   DAYS_EMPLOYED

-   DAYS_ID_PUBLISH

-   OWN_CAR_AGE

-   FLAG_EMP_PHONE FLAG_WORK_PHONE FLAG_PHONE FLAG_EMAIL CNT_FAM_MEMBERS REGION_RATING_CLIENT_W_CITY REG_CITY_NOT_LIVE_CITY EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3 DEF_30_CNT_SOCIAL_CIRCLE DAYS_LAST_PHONE_CHANGE FLAG_DOCUMENT_2 FLAG_DOCUMENT_3 FLAG_DOCUMENT_5 FLAG_DOCUMENT_6 FLAG_DOCUMENT_8 FLAG_DOCUMENT_13 FLAG_DOCUMENT_14 FLAG_DOCUMENT_16 FLAG_DOCUMENT_18 AMT_REQ_CREDIT_BUREAU_YEAR

```{r clusters}
# attempt to cluster the numeric predictors
hc <- hclust(as.dist(1 - abs(cor_matrix)))

cor_matrix_ordered <- cor_matrix[hc$order, hc$order]

corrplot(cor_matrix_ordered, order = "hclust", addrect = 5, tl.cex = 0.2) # Adds rectangles to identify clusters

```

### NOTE ON THIS SECTION

Need more time to find these predictors.

## Character Predictors

I will look at character type predictors in another way for simplicity. We can see that ORGANIZATION_TYPE has a lot of levels, so I will omit those.

```{r}
# creating character 
character_app_train <- app_train %>%
  mutate(TARGET = factor(TARGET)) %>% 
  select(-SK_ID_CURR) %>%
  select(where(~ !is.numeric(.))) %>%
  mutate_if(is.character, as.factor)

character_app_train %>%
  summarise(across(where(is.factor), ~nlevels(.))) %>%
  print()
```

Using a logistic regression, the following variables have the highest correlation with the predictor variable. I won't show the entire model.

Include:

-   NAME_CONTRACT_TYPE

-   CODE_GENDER (?)

-   FLAG_OWN_CAR

-   FLAG_OWN_REALTY

-   NAME_FAMILY_STATUS

-   OCCUPATION_TYPE

-   EMERGENCYSTATE_MODE

```{r}

categorical_vars <- setdiff(names(character_app_train), "TARGET")

chi_sq_results <- list()

for(var in categorical_vars) {

  character_app_train[[var]] <- as.factor(character_app_train[[var]])
  
  test_result <- chisq.test(table(character_app_train[[var]], character_app_train$TARGET))

  chi_sq_results[[var]] <- test_result
}

chi_sq_results

```
```{r}

# Get the names of all categorical variables excluding the target
categorical_vars <- setdiff(names(character_app_train), "TARGET")

# Initialize an empty list to store the results
proportions_list <- list()

# Loop through each categorical variable
for(cat_var in categorical_vars) {
  # Calculate proportions
  proportions <- character_app_train %>%
    count(!!sym(cat_var), TARGET) %>%  # Count combinations of categorical variable and TARGET
    group_by(!!sym(cat_var)) %>%  # Group by the categorical variable
    mutate(Proportion = n / sum(n)) %>%  # Calculate proportion within each level of the categorical variable
    ungroup()  # Remove the grouping
  
  # Store the result
  proportions_list[[cat_var]] <- proportions
}

# The proportions_list object now contains the proportions for each categorical variable
# Example to view results for the first variable
print(proportions_list[[4]])


```
