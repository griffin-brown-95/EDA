---
title: "EDA - Home Credit"
author: "Griffin Brown"
affiliation-title: "University of Utah"
date: last-modified
title-block-style: default
title-block-banner: "#219ebc"
format: 
  html:
      embed-resources: true
      theme: flatly
      code-block-bg: true
      code-block-border-left: "#3ABFC0"
      highlight-style: printing
      toc: true
execute:
    message: false
    warning: false
    error: false
    echo: true
---

# Introduction

This document serves as an exploration of the the Home Credit Default Risk project. Home Credit serves as an outlet for people to obtain a loan where they may have a lack in traditional credit history. Using numerous variables about each person, the goal is to predict who will potentially default on a loan without using these new predictors.

What we will be exploring in this document is the main application data. This covers 122 variables about each applicant to use as predictors. We will split this data by numeric and character type data and find what jumps out as strong predictors.

```{r setup, include=FALSE}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(skimr)
library(janitor)
library(fastDummies)
library(corrplot)
library(corrr)
library(knitr)
library(scales)
library(ggrepel)
```

# Description

```{r data}

app_train <- read.csv("C:\\Users\\gbrown\\OneDrive - uolf.org\\Desktop\\Masters\\IS 6812-001 Seminar 2\\home_credit\\application_train.csv")

```

```{r}
app_train %>% 
  dim()

sapply(app_train,class) %>% 
  table()
```

What we are looking at is a dataset with 307,508 rows and 122 columns. There are 16 character columns, and 106 numeric/integer.

## Approval Rating

We can see that the approval for a loan is fairly rare, with a 8% approval rating.

```{r glance}
#app_train$TARGET <- factor(app_train$TARGET)

app_train %>%  
  count(TARGET) %>% 
  mutate(perc = n/sum(n))
```

Here is the distribution visually.

```{r glance_graph}
app_train %>% 
  mutate(TARGET = factor(TARGET)) %>% 
  count(TARGET) %>% 
  mutate(perc = n / sum(n)) %>% 
  ggplot(aes(x = TARGET, y = perc)) +
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic()
```

# Missing Data

There is a lot of missing data in the set. Roughly half of the columns have missing data, with 52 being over 10% missing. To me, this does leave much room for imputation. However, the amount of N/A's may show that a variable be treated as it's own category instead, as the lack of data could be a predictor of the Target variable.

```{r}
count_missings <- function(x) sum(is.na(x))

# missing values expressed as percentage                                  
missings <- app_train %>%
  summarize_all(count_missings) %>% 
  mutate_all(~ . / nrow(app_train) * 100)

# number of missing columns over 10%
sum(select(missings, where(~. > 10)) != 0)

```

I chose to experiment with this idea, creating a scatter plot showing the number of missing values vs unique answers to each variable. What I thought this might show me is if a variable had an incredibly high number of missing values, but a low amount of unique answers, this may be an indicator that the variable be categorized. For instance, perhaps a count of children could have a low number of unique answers, but "0" could actually be N/A.

```{r}
# unique counts of each variable
unique_counts <- app_train %>% 
  summarise(across(everything(), n_distinct))

# create table of these values
uniq_vs_miss <- tibble(
  variable = names(app_train),
  unique_counts = unlist(unique_counts),
  missings = unlist(missings)
)

# create the scatter plot
uniq_vs_miss %>% 
  filter(variable != "SK_ID_CURR",
         missings > .1,
         unique_counts < 20) %>% 
  ggplot(aes(x = unique_counts, y = missings)) +
  geom_point() +
  geom_text_repel(aes(label = variable),size = 2, show.legend = FALSE) +
  labs(x = "Unique Counts", y = "Missing Values", title = "Scatter Plot of Unique Counts vs Missing Values") +
  theme_minimal()
```

AMT_REQ_CREDIT_BUREAU_HOUR seems to be one of the only variables that might fit this idea, and this represents "Number of enquiries to Credit Bureau about the client one hour before application" which is joined by the same type of variable by day, week, and quarter, so my theory may not have a strong base.

# Data Cleaning

There are a couple weird looking data points, DAYS_EMPLOYED and AMT_INCOME_TOTAL immediately jumped out at me. I will not show the summary for readers sake.

```{r}
# app_train %>% 
#   summary()
```

### DAYS_EMPLOYED

Looking at DAYS_EMPLOYED, there seems to be a huge positive number (we expect negative) of 365243. This is particularly in the "Pensioner" NAME_INCOME_TYPE category.

```{r}
# this plot serves to add all the DAYS_EMPLOYED up by NAME_INCOME_TYPE
app_train %>% 
  group_by(NAME_INCOME_TYPE) %>%
  summarize(Total_DAYS_EMPLOYED = sum(DAYS_EMPLOYED, na.rm = TRUE)) %>% 
  ggplot(aes(x = NAME_INCOME_TYPE, y = Total_DAYS_EMPLOYED, fill = NAME_INCOME_TYPE)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We can further see that this number seems to be some arbitrary number that is assigned to this category that is repeated 55,374 times. A pensioner probably had a date set to some day in the future. We will instead use 0 instead of this number.

```{r}
app_train %>% 
  select(DAYS_EMPLOYED) %>% 
  max()

app_train %>% 
  filter(DAYS_EMPLOYED == 365243) %>% 
  nrow()
```

### AMT_INCOME_TOTAL

This variable has some outliers as well. It looks to me like this is their income multiplied by 100. The stakeholder should be followed up with in order to figure this out for sure. Either way, the top responses do not make sense. I will take these rows out.

```{r}

# huge outliers
app_train %>% 
  mutate(TARGET = factor(TARGET)) %>% 
  ggplot()+
  geom_boxplot(aes(x = TARGET, y = AMT_INCOME_TOTAL))+
  scale_y_continuous(labels = scales::comma)

# top AMT_INCOME_TOTAL
app_train %>% 
  select(AMT_INCOME_TOTAL) %>% 
  arrange(desc(AMT_INCOME_TOTAL)) %>% 
  slice_max(order_by = AMT_INCOME_TOTAL, n = 10)
```

The question remains, how would we like to approach these two variables. As a pensioner, maybe they never have worked, so perhaps 0 would work as a replacement to 365243. This can easily be changed with further context. As I mentioned before, I will be taking the top outliers for AMT_TOTAL_INCOME out of the dataset completely. I will also be using 10% missing as a cutoff.

```{r}
# mean_days_employed <- app_train %>% 
  # filter(DAYS_EMPLOYED != 365243) %>% 
  # summarise(mean_value = mean(DAYS_EMPLOYED, na.rm = TRUE)) %>% 
  # pull(mean_value)

# create new 'train' df that accounts for the changes we would like to make
train <- app_train %>% 
  mutate(DAYS_EMPLOYED = ifelse(DAYS_EMPLOYED == 365243,
                                0,
                                DAYS_EMPLOYED)) %>% 
  filter(AMT_INCOME_TOTAL <= 9000000) %>% 
  select_if(~ sum(is.na(.)) / nrow(app_train) < 0.1)
```

# Splitting the Data

## Numeric Predictors

```{r mean_fxn, include = FALSE}

# function to create mean for numeric variables
# app_train[] <- lapply(app_train, function(x) {
#   if(is.numeric(x)) {
#     x[is.na(x)] <- median(x, na.rm = TRUE)
#   }
#   return(x)
# })

## no more missing values, no need to display
# app_train %>%
#   summarize_all(count_missings)
```

### Correlation Matrix

I will use a correlation matrix to find strong numeric predictors. We see the strongest correlation at 15%, but drops off quite quickly.

```{r}
numerical_app_train <- train %>% 
  select(-SK_ID_CURR) %>%
  select(where(is.numeric))

cor_matrix <- cor(numerical_app_train, use = "complete.obs")
cor_matrix['TARGET',] %>% 
  abs() %>%
  sort(decreasing = TRUE) %>% 
  # head(50) %>% 
  kable(caption = 'Top Correlations with TARGET')

```

```{r clusters, include = FALSE}
# # attempt to cluster the numeric predictors
# hc <- hclust(as.dist(1 - abs(cor_matrix)))
# 
# cor_matrix_ordered <- cor_matrix[hc$order, hc$order]
# 
# corrplot(cor_matrix_ordered, order = "hclust", addrect = 5, tl.cex = 0.2) # Adds rectangles to identify clusters

```

## Character Predictors

I will look at character type predictors in another way for simplicity. We can see that ORGANIZATION_TYPE has a lot of levels, so I will omit those.

```{r}
# creating character dataframe
character_app_train <- train %>%
  mutate(TARGET = factor(TARGET)) %>% 
  select(-SK_ID_CURR) %>%
  select(where(~ !is.numeric(.))) %>%
  mutate_if(is.character, as.factor)

character_app_train %>%
  select(where(is.factor)) %>%
  summarise(across(everything(), ~nlevels(.))) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "n_levels") %>%
  ggplot(aes(x = variable, y = n_levels)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Variable", y = "Number of Levels", title = "Number of Levels in Factor Variables") +
  theme(legend.position = "none")
```

Next we will break down each of the categorical variables as a comparison of the Target outcome to the majority class to identify categories that stick out.

```{r}
overall_target_prop <- train %>%  
  mutate(TARGET = as.factor(TARGET)) %>% 
  count(TARGET) %>% 
  mutate(perc = n / sum(n))

# get target default values as variable
target_0 <- overall_target_prop[1,3]
target_1 <- overall_target_prop[2,3]

```

```{r}
categorical_vars <- setdiff(names(character_app_train), 'TARGET')

proportions_list <- list()

threshold <- 0.4

for(cat_var in categorical_vars) {
  proportions <- character_app_train %>%
    count(!!sym(cat_var), TARGET, name = "n") %>%
    group_by(!!sym(cat_var)) %>%
    mutate(proportion = n / sum(n)) %>%
    ungroup() %>%
    mutate(Variable = cat_var, Category = as.character(!!sym(cat_var))) %>%
    select(Variable, Category, TARGET, n, proportion)
  
  proportions_list[[cat_var]] <- proportions
}

# Combine all proportions into a single dataframe, add other columns
combined_proportions <- bind_rows(proportions_list) %>% 
  mutate(default_target = ifelse(TARGET == 0, target_0, target_1),
         difference = abs(proportion - default_target))
combined_proportions %>% 
  arrange(desc(difference)) %>% 
  filter(n > 1000) %>% 
  head(10)

```

# Results

In summary, I identified columns that we could omit due to missing data, adjusted outliers and weird pieces of data to create a more workable dataset. I then split this between numeric and character data. With the numeric data, correlations were shown between the target and the other variables. With the character/categorical data, we found identifiers of high difference between the actual proportion of the target and the default majority class proportion of the target variable. Using this going forward, a modeling will become much easier.
