---
title: "EDA - Home Credit"
author: "Griffin Brown"
affiliation-title: "University of Utah"
date: last-modified
title-block-style: default
title-block-banner: "#219ebc"
format: 
  html:
      embed-resources: true
      theme: flatly
      code-block-bg: true
      code-block-border-left: "#3ABFC0"
      highlight-style: printing
      toc: true
execute:
    message: false
    warning: false
    error: false
    echo: true
---
#changes
## Load Packages

```{r setup}
library(tidyverse)
library(rpart)
library(rpart.plot)
library(skimr)
library(janitor)
library(fastDummies)
library(corrplot)
```

## Load Data Sets

```{r data}

app_train <- read.csv("C:\\Users\\gbrown\\OneDrive - uolf.org\\Desktop\\Masters\\IS 6812-001 Seminar 2\\home_credit\\application_train.csv")

```

## A quick glance

We can see that the approval for a loan is fairly rare, with a 8% approval rating.

```{r glance}
app_train$TARGET <- factor(app_train$TARGET)

app_train %>% 
  count(TARGET) %>% 
  mutate(perc = n/sum(n))
```

Here is the distribution visually.

```{r glance graph}
app_train %>% 
  count(TARGET) %>% 
  mutate(perc = n / sum(n)) %>% 
  ggplot(aes(x = TARGET, y = perc)) +
  geom_bar(stat = 'identity') +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_classic()
```

## Find Missing Values

There is a lot of missing data in the set.

```{r}

count_missings <- function(x) sum(is.na(x))

# no need to display all the missing columns, but 91 have missing values.
# app_train %>% 
#   summarize_all(count_missings) %>% 
#   select_if(function(x) x > 0)

```

## Weird looking data

There are a couple weird looking data points, DAYS_EMPLOYED and AMT_INCOME_TOTAL immediately jumped out at me. I will not show the summary for readers sake.

```{r}
# app_train %>% 
#   summary()
```

## Data Cleaning

### DAYS_EMPLOYED

Looking at DAYS_EMPLOYED, there seems to be a huge positive number (we expect negative) of 365243. This is particularly in the "Pensioner" NAME_INCOME_TYPE category.

```{r}
# this plot serves to add all the DAYS_EMPLOYED up by NAME_INCOME_TYPE
app_train %>% 
  group_by(NAME_INCOME_TYPE) %>%
  summarize(Total_DAYS_EMPLOYED = sum(DAYS_EMPLOYED, na.rm = TRUE)) %>% 
  ggplot(aes(x = NAME_INCOME_TYPE, y = Total_DAYS_EMPLOYED, fill = NAME_INCOME_TYPE)) +
  geom_bar(stat = "identity") +
  scale_y_continuous(labels = scales::comma) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We can further see that this number seems to be some arbitrary number that is assigned to this category.

```{r}
app_train %>% 
  filter(DAYS_EMPLOYED == 365243) %>% 
  nrow()
```

### AMT_INCOME_TOTAL

This variable has some outliers as well. It looks to me like this is their income multiplied by 100. The stakeholder should be followed up with in order to figure this out for sure. Either way, the top responses do not make sense. I will take these rows out.

```{r}

# huge outliers
app_train %>% 
  ggplot()+
  geom_boxplot(aes(x= TARGET, y= AMT_INCOME_TOTAL))+
  scale_y_continuous(labels = scales::comma)

# top AMT_INCOME_TOTAL
app_train %>% 
  select(AMT_INCOME_TOTAL) %>% 
  arrange(desc(AMT_INCOME_TOTAL)) %>% 
  slice_max(order_by = AMT_INCOME_TOTAL, n = 10)
```

The question remains, how would we like to approach these two variables. As a pensioneer, maybe they never have worked, so perhaps 0 would work as a replacement to 365243. For now, I will give it the mean but this can easily be changed with further context. As I mentioned before, I will be taking the top outliers for AMT_TOTAL_INCOME out of the dataset completely.

```{r}
mean_days_employed <- app_train %>% 
  filter(DAYS_EMPLOYED != 365243) %>% 
  summarise(mean_value = mean(DAYS_EMPLOYED, na.rm = TRUE)) %>% 
  pull(mean_value)

app_train <- app_train %>% 
  mutate(DAYS_EMPLOYED = ifelse(DAYS_EMPLOYED == 365243,
                                mean_days_employed,
                                DAYS_EMPLOYED)) %>% 
  filter(AMT_INCOME_TOTAL <= 9000000)
```

## Numeric Predictors

For missing values, I will be giving the mean to NA variables.

```{r}

# function to create mean for numeric variables
app_train[] <- lapply(app_train, function(x) {
  if(is.numeric(x)) {
    x[is.na(x)] <- mean(x, na.rm = TRUE)
  }
  return(x)
})

## no more missing values, no need to display
# app_train %>%
#   summarize_all(count_missings)
```

### I will use a correlation matrix to find strong numeric predictors.

```{r}
numerical_app_train <- app_train %>% 
  select(-SK_ID_CURR) %>%
  select(where(is.numeric))
  
cor_matrix <- cor(numerical_app_train, use = "complete.obs")
# print(cor_matrix)
corrplot(cor_matrix, method = "color", type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45, tl.cex = 0.2)

```

```{r clusters}
# attempt to cluster the numeric predictors
hc <- hclust(as.dist(1 - abs(cor_matrix)))

cor_matrix_ordered <- cor_matrix[hc$order, hc$order]

corrplot(cor_matrix_ordered, order = "hclust", addrect = 5, tl.cex = 0.2) # Adds rectangles to identify clusters

```
### NOTE ON THIS SECTION
Need more time to find these predictors.


## Character Predictors

I will look at character type predictors in another way for simplicity. We can see that ORGANIZATION_TYPE has a lot of levels, so I will omit those.

```{r}
# creating character 
character_app_train <- app_train %>%
  select(-SK_ID_CURR) %>%
  select(where(~ !is.numeric(.))) %>%
  mutate_if(is.character, as.factor)

character_app_train %>%
  summarise(across(where(is.factor), ~nlevels(.))) %>%
  print()
```

Using a logistic regression, the following variables have the highest correlation with the predictor variable. I won't show the entire model.

Include:

-   NAME_CONTRACT_TYPE

-   CODE_GENDER (?)

-   FLAG_OWN_CAR

-   FLAG_OWN_REALTY

-   NAME_FAMILY_STATUS

-   OCCUPATION_TYPE

-   EMERGENCYSTATE_MODE

```{r}
# glm(TARGET ~ . - ORGANIZATION_TYPE, family = binomial, data = character_app_train) %>% summary()

```

## Other File Exploration
This I will need a bit more time as well. The idea is simple to create summaries based off of SK_ID_CURR and join on the train data.
